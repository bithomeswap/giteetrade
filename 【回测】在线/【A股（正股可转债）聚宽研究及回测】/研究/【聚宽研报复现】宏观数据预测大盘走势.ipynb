{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score,recall_score\n",
    "from sklearn.feature_selection import SelectKBest,SelectPercentile,SelectFromModel,chi2,f_classif,mutual_info_classif,RFE\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC,LinearSVR,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from jqdata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2005-01-01'\n",
    "end_date = '2015-12-31'\n",
    "\n",
    "test_start_date = '2016-01-01'\n",
    "test_end_date = '2018-11-30'\n",
    "\n",
    "start_year = start_date[:4]\n",
    "end_year = end_date[:4]\n",
    "\n",
    "select_index = '000300.XSHG'\n",
    "n = 3 #data_y延期n月\n",
    "\n",
    "stat_quarter = '2015-03'\n",
    "stat_month = '2015-02'\n",
    "\n",
    "seq_len = 5 #lstm back num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_list(start_year,end_year):\n",
    "    sy = int(start_year)\n",
    "    ey = int(end_year)\n",
    "    l = []\n",
    "    for i in range(sy,ey+1):\n",
    "        l.append(str(i))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter_list(start_year,end_year):\n",
    "    sy = int(start_year)\n",
    "    ey = int(end_year)\n",
    "    l = []\n",
    "    for y in range(sy,ey+1):\n",
    "        for q in range(3,13,3):\n",
    "            if q < 10:\n",
    "                s = str(y) + '-' + '0' + str(q)\n",
    "                l.append(s)\n",
    "            else:\n",
    "                s = str(y) + '-' +  str(q)\n",
    "                l.append(s)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_list(start_date,end_date):\n",
    "    sy = int(start_date[:4])\n",
    "    ey = int(end_date[:4])\n",
    "    sm = int(start_date[5:7])\n",
    "    em = int(end_date[5:7])\n",
    "    l = []\n",
    "    for y in range(sy,ey+1):\n",
    "        if y == sy:\n",
    "            for i in range(sm,13):\n",
    "                if i< 10:\n",
    "                    s = str(y) + '-' + '0' + str(i)\n",
    "                    l.append(s)\n",
    "                else:\n",
    "                    s = str(y) + '-' +  str(i)      \n",
    "                    l.append(s)\n",
    "               \n",
    "        elif y == ey:\n",
    "            for i in range(1,em+1):\n",
    "                if i < 10:\n",
    "                    s = str(y) + '-' + '0' + str(i)\n",
    "                    l.append(s)\n",
    "                else:\n",
    "                    s = str(y) + '-' +  str(i)\n",
    "                    l.append(s)\n",
    "        else:           \n",
    "            for i in range(1,13):\n",
    "                if i < 10:\n",
    "                    s = str(y) + '-' + '0' + str(i)\n",
    "                    l.append(s)\n",
    "                else:\n",
    "                    s = str(y) + '-' +  str(i)\n",
    "                    l.append(s)\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##获取宏观数据\n",
    "def get_macro_data(month_list,start_date,end_date):\n",
    "        \n",
    "    #社会消费品销售总额\n",
    "    sr = macro.MAC_SALE_RETAIL_MONTH\n",
    "    q = query(sr.stat_month,sr.retail_sin,sr.retail_sin_yoy,sr.retail_acc_yoy)\\\n",
    "    .filter(macro.MAC_SALE_RETAIL_MONTH.stat_month.in_(month_list))\\\n",
    "    .order_by(macro.MAC_SALE_RETAIL_MONTH.stat_month)\n",
    "    sale = macro.run_query(q).dropna(axis=1,how='all').fillna(method='ffill')\n",
    "    q_a = query(sr).filter(macro.MAC_SALE_RETAIL_MONTH.stat_month.in_(month_list))\\\n",
    "    .order_by(macro.MAC_SALE_RETAIL_MONTH.stat_month)\n",
    "    sale_a = macro.run_query(q_a).dropna(axis=1,how='all').fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    #房地产开发投资情况表\n",
    "    ie = macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH\n",
    "    q_estate = query(macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.stat_month,macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.invest,\\\n",
    "                    macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.invest_yoy)\\\n",
    "    .filter(macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.stat_month.in_(month_list))\\\n",
    "    .order_by(macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.stat_month)\n",
    "    estate = macro.run_query(q_estate)\n",
    "    \n",
    "    q_estate_a = query(ie).filter(macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.stat_month.in_(month_list)).order_by(macro.MAC_INDUSTRY_ESTATE_INVEST_MONTH.stat_month)\n",
    "    estate_a = macro.run_query(q_estate_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    #70个大中城市房屋销售价格指数(月度)\n",
    "    \n",
    "    q_70city_eatate = query(macro.MAC_INDUSTRY_ESTATE_70CITY_INDEX_MONTH.stat_month,macro.MAC_INDUSTRY_ESTATE_70CITY_INDEX_MONTH.commodity_house_idx)\\\n",
    "    .filter(macro.MAC_INDUSTRY_ESTATE_70CITY_INDEX_MONTH.stat_month.in_(month_list)).order_by(macro.MAC_INDUSTRY_ESTATE_70CITY_INDEX_MONTH.stat_month)\n",
    "    city_eatate_all = macro.run_query(q_70city_eatate).fillna(method='ffill')\n",
    "    city_eatate = city_eatate_all.groupby(['stat_month']).mean()\n",
    "\n",
    "    #黄金和外汇储备 \n",
    "    #数据从2008年开始\n",
    "    gf = macro.MAC_GOLD_FOREIGN_RESERVE\n",
    "    q_gold_foreign = query(gf.stat_date,gf.gold,gf.foreign).filter(gf.stat_date.in_(month_list)).order_by(gf.stat_date)\n",
    "    gold_foreign_0 = macro.run_query(q_gold_foreign)\n",
    "    gold_foreign_0['stat_month'] = gold_foreign_0['stat_date']\n",
    "    gold_foreign = gold_foreign_0.drop(['stat_date'],axis=1)\n",
    "    \n",
    "    q_gold_foreign_a = query(gf).filter(gf.stat_date.in_(month_list)).order_by(gf.stat_date)\n",
    "    gold_foreign_1 = macro.run_query(q_gold_foreign_a)\n",
    "    gold_foreign_1['stat_month'] = gold_foreign_1['stat_date']\n",
    "    gold_foreign_a = gold_foreign_1.drop(['stat_date'],axis=1).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    #固定资产投资\n",
    "    fi = macro.MAC_FIXED_INVESTMENT\n",
    "    q_fixed_inv = query(fi.stat_month,fi.fixed_assets_investment_yoy,fi.primary_yoy,fi.secondary_yoy,fi.tertiary_yoy,fi.centre_project_yoy)\\\n",
    "    .filter(fi.stat_month.in_(month_list)).order_by(fi.stat_month)\n",
    "    fixed_inv = macro.run_query(q_fixed_inv).fillna(method='ffill')\n",
    "    q_fixed_inv_a = query(fi).filter(fi.stat_month.in_(month_list)).order_by(fi.stat_month)\n",
    "    fixed_inv_a = macro.run_query(q_fixed_inv_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    #利用外资情况表\n",
    "    fc = macro.MAC_FOREIGN_CAPITAL_MONTH\n",
    "    q_foreign_cap = query(fc.stat_month,fc.num_acc_yoy).filter(fc.stat_month.in_(month_list)).order_by(fc.stat_month)\n",
    "    foreign_cap = macro.run_query(q_foreign_cap).fillna(method='ffill')\n",
    "    q_foreign_cap_a = query(fc).filter(fc.stat_month.in_(month_list)).order_by(fc.stat_month)\n",
    "    foreign_cap_a = macro.run_query(q_foreign_cap_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    #宏观经济景气指数\n",
    "    eb = macro.MAC_ECONOMIC_BOOM_IDX\n",
    "    q_eco_boom = query(eb.stat_month,eb.early_warning_idx,eb.consistency_idx,eb.early_warning_idx,eb.lagging_idx)\\\n",
    "    .filter(eb.stat_month.in_(month_list)).order_by(eb.stat_month)\n",
    "    economic_boom = macro.run_query(q_eco_boom)\n",
    "    q_eco_boom_a = query(eb).filter(eb.stat_month.in_(month_list)).order_by(eb.stat_month)\n",
    "    economic_boom_a = macro.run_query(q_eco_boom_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    #制造业采购经理指数（PMI）\n",
    "    mf = macro.MAC_MANUFACTURING_PMI\n",
    "    q_pmi = query(mf.stat_month,mf.pmi).filter(mf.stat_month.in_(month_list)).order_by(mf.stat_month)\n",
    "    pmi = macro.run_query(q_pmi)\n",
    "    pmi_m = pmi['pmi'] - 50 #该指数以50为中心，大于表示制造业扩张，反之表示衰退\n",
    "    pmi['pmi'] = pmi_m\n",
    "    q_pmi_a = query(mf).filter(mf.stat_month.in_(month_list)).order_by(mf.stat_month)\n",
    "    pmi_a = macro.run_query(q_pmi_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    #全国工业增长速度\n",
    "    ig = macro.MAC_INDUSTRY_GROWTH\n",
    "    q_industry_growth = query(ig.stat_month,ig.growth_yoy,ig.growth_acc).filter(ig.stat_month.in_(month_list)).order_by(ig.stat_month)\n",
    "    industry_growth = macro.run_query(q_industry_growth).fillna(method='ffill')\n",
    "    industry_growth_diff = industry_growth['growth_acc'].diff().fillna(0)\n",
    "    industry_growth['growth_acc_diff'] = industry_growth_diff\n",
    "    \n",
    "    q_industry_growth_a = query(ig).filter(ig.stat_month.in_(month_list)).order_by(ig.stat_month)\n",
    "    industry_growth_a = macro.run_query(q_industry_growth_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    #全国工业企业主要经济指标\n",
    "    ii = macro.MAC_INDUSTRY_INDICATOR\n",
    "    q_industry_indicator = query(ii.stat_month,ii.enterprise_value_acc,ii.loss_enterprise_ratio_acc,\\\n",
    "                               ii.total_interest_ratio_acc).filter(ii.stat_month.in_(month_list)).order_by(ii.stat_month)\n",
    "    industry_indicator = macro.run_query(q_industry_indicator)\n",
    "    industry_indicator_diff = industry_indicator['enterprise_value_acc'].diff().fillna(method='bfill')\n",
    "    industry_indicator['enterprise_value_acc_diff'] = industry_indicator_diff/industry_indicator['enterprise_value_acc'].shift().fillna(method='bfill')\n",
    "    industry_indicator['loss_enterprise_ratio_acc_diff'] = industry_indicator['loss_enterprise_ratio_acc'].diff()\n",
    "    industry_indicator['total_interest_ratio_acc_diff'] = industry_indicator['total_interest_ratio_acc'].diff()\n",
    "    industry_indicator = industry_indicator.fillna(method='bfill')\n",
    "    l = ['stat_month','enterprise_value_acc_diff','loss_enterprise_ratio_acc_diff','total_interest_ratio_acc_diff']\n",
    "    industry_indicator = industry_indicator[l]\n",
    "    \n",
    "    q_industry_indicator_a = query(ii).filter(ii.stat_month.in_(month_list)).order_by(ii.stat_month)\n",
    "    industry_indicator_a = macro.run_query(q_industry_indicator_a).dropna(how='all',axis=1).fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    #月度宏观经济指标\n",
    "    month_macro_indicators = [sale,estate,fixed_inv,foreign_cap,economic_boom,pmi,industry_growth,industry_indicator]\n",
    "    mg = sale['stat_month'].to_frame()\n",
    "    for ind in month_macro_indicators:\n",
    "        mg = pd.merge(mg,ind,left_on=['stat_month'],right_on=['stat_month'],how='left')\n",
    "    res = mg.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    month_macro_indicators_a = [sale_a,estate_a,fixed_inv_a,foreign_cap_a,economic_boom_a,\\\n",
    "                                pmi_a,industry_growth_a,industry_indicator_a]\n",
    "    \n",
    "    for ind in month_macro_indicators_a:\n",
    "        mg_a = pd.merge(mg,ind,left_on=['stat_month'],right_on=['stat_month'],how='left')\n",
    "    res_a = mg_a.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    price = get_price(select_index,start_date=start_date,end_date=end_date,fields=['close'])\n",
    "\n",
    "    data = [res,res_a,price]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取月度价格数据\n",
    "def get_price_month_data(price,n='mean',mean_num=1):\n",
    "    '''\n",
    "    :param price: 输入价格数据，index为datetime类型\n",
    "    :param type: 计算方式，’mean‘取月平均值，若为int,则从第几个交易日开始计算均值，长度为mean_num，\n",
    "    :param mean_num: 计算均值的长度\n",
    "    :return:\n",
    "    '''\n",
    "    ind = list(price.index)\n",
    "    s_ind = [datetime.datetime.strftime(i, '%Y%m%d') for i in ind]\n",
    "    price.index = s_ind\n",
    "    num_ind = [int(i) for i in s_ind]\n",
    "    cut_ind = [int(i / 100) for i in num_ind]\n",
    "    cut_s_ind = [(str(i)[:4] + '-' + str(i)[4:]) for i in cut_ind]\n",
    "    price['stat_date'] = cut_s_ind\n",
    "    if n == 'mean':\n",
    "        res = price.groupby(by=['stat_date']).mean()\n",
    "    else:\n",
    "        ind_sig = list(set(price['stat_date'].values))\n",
    "        index_list = []\n",
    "        mean_list = []\n",
    "        for ind in ind_sig:\n",
    "            df = price[price['stat_date']==ind]\n",
    "            sel_df = df.iloc[n-1:n+mean_num-1,0]\n",
    "            index = list(sel_df.index)\n",
    "            if len(index) == 0:\n",
    "                continue\n",
    "            index = index[0]\n",
    "            index_list.append(index)\n",
    "            mean_df = sel_df.mean()\n",
    "            mean_list.append(mean_df)\n",
    "        res_df = pd.DataFrame(mean_list,index=index_list,columns=['month_price'])\n",
    "        res = res_df.sort_index()\n",
    "        res_index = list(res.index)\n",
    "        ind_s_cut = [i[:4] + '-' + i[4:6] for i in res_index]\n",
    "        res.index = ind_s_cut\n",
    "    return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pure_values(data):\n",
    "    '''\n",
    "    获取纯净数值，将DataFrame中的非数值项剔除，例如‘code’项（str）\n",
    "    input:\n",
    "    data:pd.DataFrame,index为股票代码\n",
    "    putput:\n",
    "    DataFrame：只含数值项\n",
    "    '''\n",
    "    columns = list(data.columns)\n",
    "    for column in columns:\n",
    "        if not(isinstance(data[column][0],int) or isinstance(data[column][0],float)):\n",
    "            data = data.drop([column],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_and_standarlize(data, qrange=[0.05, 0.95], axis=0):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        if axis == 0:\n",
    "            q_down = data.quantile(qrange[0])\n",
    "            q_up = data.quantile(qrange[1])\n",
    "            col = data.columns\n",
    "            for n in col:\n",
    "                data[n][data[n] > q_up[n]] = q_up[n]\n",
    "                data[n][data[n] < q_down[n]] = q_down[n]\n",
    "            data = (data - data.mean()) / data.std()\n",
    "            data = data.fillna(0)\n",
    "        else:\n",
    "            data = data.stack()\n",
    "            data = data.unstack(0)\n",
    "            q_down = data.quantile(qrange[0])\n",
    "            q_up = data.quantile(qrange[1])\n",
    "            col = data.columns\n",
    "            for n in col:\n",
    "                data[n][data[n] > q_up[n]] = q_up[n]\n",
    "                data[n][data[n] < q_down[n]] = q_down[n]\n",
    "            data = (data - data.mean()) / data.std()\n",
    "            data = data.stack().unstack(0)\n",
    "            data = data.fillna(0)\n",
    "\n",
    "    elif isinstance(data, pd.Series):\n",
    "        q_down = data.quantile(qrange[0])\n",
    "        q_up = data.quantile(qrange[1])\n",
    "        data[data > q_up] = q_up\n",
    "        data[data < q_down] = q_down\n",
    "        data = (data - data.mean()) / data.std()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_class(data):\n",
    "    '''\n",
    "    对数据进行分类标记\n",
    "    '''\n",
    "    data_diff = data.diff(n)\n",
    "    data_diff[data_diff > 0] = 1\n",
    "    data_diff[data_diff < 0] = 0\n",
    "    #data_diff[data_diff == 2] = -1\n",
    "    #data_diff[data_diff == -2] = 1\n",
    "    return data_diff\n",
    "\n",
    "def get_final_data(input_x,input_y):\n",
    "    input_y = input_y.shift(-n).to_frame().fillna(method='ffill')\n",
    "    data_m = pd.merge(input_x,input_y,left_index=True,right_index=True,how='right')\n",
    "    columns_m = data_m.columns\n",
    "    data_x = data_m[columns_m[:-1]]\n",
    "    data_y = data_m[columns_m[-1]]\n",
    "    return data_x,data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection():\n",
    "    '''\n",
    "    特征选择：\n",
    "    identify_collinear：基于相关系数，删除小于correlation_threshold的特征\n",
    "    identify_importance_lgbm：基于LightGBM算法，得到feature_importance,选择和大于p_importance的特征\n",
    "    filter_select:单变量选择，指定k,selectKBest基于method提供的算法选择前k个特征，selectPercentile选择前p百分百的特征\n",
    "    wrapper_select:RFE，基于estimator递归特征消除，保留n_feature_to_select个特征\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.filter_supports = None #bool型，特征是否被选中\n",
    "        self.wrapper_supports = None\n",
    "        self.embedded_supports = None\n",
    "        self.lgbm_columns = None  #选择的特征\n",
    "        self.filter_columns = None\n",
    "        self.wrapper_columns = None\n",
    "        self.embedded_columns = None\n",
    "        self.record_collinear = None #自相关矩阵大于门限值\n",
    "        \n",
    "    def identify_collinear(self, data, correlation_threshold):\n",
    "\n",
    "        columns = data.columns\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "\n",
    "        # Calculate the correlations between every column\n",
    "        corr_matrix = data.corr()\n",
    "        \n",
    "        self.corr_matrix = corr_matrix\n",
    "    \n",
    "        # Extract the upper triangle of the correlation matrix\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "        # Select the features with correlations above the threshold\n",
    "        # Need to use the absolute value\n",
    "        to_drop = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]\n",
    "        obtain_columns = [column for column in columns if column not in to_drop]\n",
    "        self.columns = obtain_columns\n",
    "        # Dataframe to hold correlated pairs\n",
    "        record_collinear = pd.DataFrame(columns = ['drop_feature', 'corr_feature', 'corr_value'])\n",
    "\n",
    "        # Iterate through the columns to drop\n",
    "        for column in to_drop:\n",
    "\n",
    "            # Find the correlated features\n",
    "            corr_features = list(upper.index[upper[column].abs() > correlation_threshold])\n",
    "\n",
    "            # Find the correlated values\n",
    "            corr_values = list(upper[column][upper[column].abs() > correlation_threshold])\n",
    "            drop_features = [column for _ in range(len(corr_features))]    \n",
    "\n",
    "            # Record the information (need a temp df for now)\n",
    "            temp_df = pd.DataFrame.from_dict({'drop_feature': drop_features,\n",
    "                                             'corr_feature': corr_features,\n",
    "                                             'corr_value': corr_values})\n",
    "\n",
    "            # Add to dataframe\n",
    "            record_collinear = record_collinear.append(temp_df, ignore_index = True)\n",
    "\n",
    "        self.record_collinear = record_collinear\n",
    "        return data[obtain_columns]\n",
    "     \n",
    "        \n",
    "    def identify_importance_lgbm(self, features, labels,p_importance=0.8, eval_metric='auc', task='classification', \n",
    "                                 n_iterations=10, early_stopping = True):\n",
    "        \n",
    "        # One hot encoding\n",
    "        data = features\n",
    "        features = pd.get_dummies(features)\n",
    "\n",
    "        # Extract feature names\n",
    "        feature_names = list(features.columns)\n",
    "\n",
    "        # Convert to np array\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels).reshape((-1, ))\n",
    "\n",
    "        # Empty array for feature importances\n",
    "        feature_importance_values = np.zeros(len(feature_names))\n",
    "        \n",
    "        #print('Training Gradient Boosting Model\\n')\n",
    "        \n",
    "        # Iterate through each fold\n",
    "        for _ in range(n_iterations):\n",
    "\n",
    "            if task == 'classification':\n",
    "                model = lgb.LGBMClassifier(n_estimators=100, learning_rate = 0.05, verbose = -1)\n",
    "\n",
    "            elif task == 'regression':\n",
    "                model = lgb.LGBMRegressor(n_estimators=100, learning_rate = 0.05, verbose = -1)\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Task must be either \"classification\" or \"regression\"')\n",
    "                \n",
    "            # If training using early stopping need a validation set\n",
    "            if early_stopping:\n",
    "                \n",
    "                train_features, valid_features, train_labels, valid_labels = train_test_split(features, labels, test_size = 0.15)\n",
    "\n",
    "                # Train the model with early stopping\n",
    "                model.fit(train_features, train_labels, eval_metric = eval_metric,\n",
    "                          eval_set = [(valid_features, valid_labels)],\n",
    "                           verbose = -1)\n",
    "                \n",
    "                # Clean up memory\n",
    "                gc.enable()\n",
    "                del train_features, train_labels, valid_features, valid_labels\n",
    "                gc.collect()\n",
    "                \n",
    "            else:\n",
    "                model.fit(features, labels)\n",
    "\n",
    "            # Record the feature importances\n",
    "            feature_importance_values += model.feature_importances_ / n_iterations\n",
    "\n",
    "        feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "\n",
    "        # Sort features according to importance\n",
    "        feature_importances = feature_importances.sort_values('importance', ascending = False).reset_index(drop = True)\n",
    "\n",
    "        # Normalize the feature importances to add up to one\n",
    "        feature_importances['normalized_importance'] = feature_importances['importance'] / feature_importances['importance'].sum()\n",
    "        feature_importances['cumulative_importance'] = np.cumsum(feature_importances['normalized_importance'])\n",
    "        select_df = feature_importances[feature_importances['cumulative_importance']<=p_importance]\n",
    "        select_columns = select_df['feature']\n",
    "        self.lgbm_columns = list(select_columns.values)\n",
    "        res = data[self.columns]\n",
    "        return res\n",
    "        \n",
    "    def filter_select(self, data_x, data_y, k=None, p=50,method=f_classif):\n",
    "        columns = data_x.columns\n",
    "        if k != None:\n",
    "            model = SelectKBest(method,k)\n",
    "            res = model.fit_transform(data_x,data_y)\n",
    "            supports = model.get_support()\n",
    "        else:\n",
    "            model = SelectPercentile(method,p)\n",
    "            res = model.fit_transform(data_x,data_y)\n",
    "            supports = model.get_support()\n",
    "        self.filter_support_ = supports\n",
    "        self.filter_columns = columns[supports]\n",
    "        return res\n",
    "    \n",
    "    def wrapper_select(self,data_x,data_y,n,estimator):\n",
    "        columns = data_x.columns\n",
    "        model = RFE(estimator=estimator,n_features_to_select=n)\n",
    "        res = model.fit_transform(data_x,data_y)\n",
    "        supports = model.get_support() #标识被选择的特征在原数据中的位置\n",
    "        self.wrapper_supports = supports\n",
    "        self.wrapper_columns = columns[supports]\n",
    "        return res\n",
    "    \n",
    "    def embedded_select(self,data_x,data_y,estimator,threshold=None):\n",
    "        columns = data_x.columns\n",
    "        model = SelectFromModel(estimator=estimator,prefit=False,threshold=threshold)\n",
    "        res = model.fit_transform(data_x,data_y)\n",
    "        supports = model.get_support()\n",
    "        self.embedded_supports = supports\n",
    "        self.embedded_columns = columns[supports]\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调参时计算召回率和准确率\n",
    "def lstm_recall(prediction,y,n=1,thr=0.5):\n",
    "    len_p = len(prediction)\n",
    "    l = 0\n",
    "    z = 0\n",
    "    res = []\n",
    "    if n == 1:\n",
    "        for i in range(len_p):\n",
    "            if (prediction[i]>= thr):\n",
    "                l = l+1\n",
    "                if (y[i] ==1):\n",
    "                    z = z+1\n",
    "    elif n==0:\n",
    "         for i in range(len_p):\n",
    "            if (prediction[i]<=thr):\n",
    "                l = l+1\n",
    "                if (y[i] ==0):\n",
    "                    z = z+1\n",
    "    lstm_recall = z/l\n",
    "    return lstm_recall\n",
    "\n",
    "def lstm_accuracy(prediction,y,thr=0.5):\n",
    "    len_p = len(prediction)\n",
    "    l = 0\n",
    "    for i in range(len_p):\n",
    "        if ((prediction[i]>=thr) & (y[i] ==1)) |  ((prediction[i]<thr) & (y[i] ==0)):\n",
    "            l = l + 1\n",
    "            \n",
    "    accuracy = l/len_p\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_output(res,buy_thr=1.6,sell_thr=0.5):\n",
    "    '''\n",
    "    基于lgbm和embedded两组特征选择数据的计算结果确定预测结果\n",
    "    buy_thr:预测股价上升的门限值，默认1.5,\n",
    "    sell_thr:预测股价下降的门限值，默认0.5\n",
    "    大于买入门限标记为1，小于卖出门限标记为-1，中间值认为买入卖出信号不强，选择观望或空仓，卖出信号可用于做空，在无法做空时认为空仓\n",
    "    \n",
    "    '''\n",
    "    length = len(res)\n",
    "    l = []\n",
    "    for i in range(length):\n",
    "        if res[i] > buy_thr:\n",
    "            l.append(1)\n",
    "        elif res[i] < sell_thr:\n",
    "            l.append(-1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_fun(n_input,train_x,train_y,predict_x,seq_len=5):\n",
    "    #LSTM\n",
    "    lr=0.1\n",
    "    lstm_size = 3  #lstm cell数量，基于数据量调整\n",
    "    epoch_num = 10  #打印次数，和n_batch相乘便是迭代次数\n",
    "    n_batch = 300\n",
    "    lookback = seq_len\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    x = tf.placeholder(tf.float32,[None,lookback,n_input])\n",
    "    y = tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([lstm_size,1],stddev=0.1))\n",
    "    biases = tf.Variable(tf.constant(0.1,shape=[1]))\n",
    "\n",
    "    def LSTM_net(x,weights,biases):\n",
    "        lstm_cell = tf.contrib.rnn.LSTMCell(lstm_size,name='basic_lstm_cell') #.BasicLSTMCell(lstm_size)\n",
    "        output,final_state = tf.nn.dynamic_rnn(lstm_cell,x,dtype=tf.float32)\n",
    "        results = tf.nn.sigmoid(tf.matmul(final_state[1],weights)+biases)\n",
    "        return results\n",
    "\n",
    "    prediction = LSTM_net(x,weights,biases)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(epoch_num):\n",
    "            for j in range(n_batch):\n",
    "                sess.run(train_step,feed_dict={x:train_x,y:train_y})\n",
    "            #train_loss = sess.run(loss,feed_dict={x:train_x,y:train_y})\n",
    "           # print('train loss is'+ str(train_loss))\n",
    "        prediction_res = sess.run(prediction,feed_dict={x:predict_x})\n",
    "    return prediction_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_time_list(start_date,test_start_date,test_end_date):\n",
    "    '''\n",
    "    使用机器学习算法计算时的时间数据\n",
    "    input:\n",
    "    start_date:取宏观数据的开始时间\n",
    "    test_start_date:预测的开始时间，也就是取宏观数据的截止时间\n",
    "    test_end_date:预测的截止时间，对期间的每一个月都要预测，每一个月都要重跑一遍预测函数，每个月的开始使用上个月28号的价格数据作为截止价格时间\n",
    "    output:\n",
    "    m_l：每一次预测时的月份列表，在此列表内跑预测函数，\n",
    "    start_date,取宏观数据和价格数据的开始时间，由全局变量定义\n",
    "    ed:取价格数据截止时间列表，顺序和m_l对应\n",
    "    '''\n",
    "    test_month = get_month_list(test_start_date,test_end_date)\n",
    "    m_l_pre = []\n",
    "    ed = []\n",
    "    for m in test_month:\n",
    "        ml = get_month_list(start_date,m)\n",
    "        m_l_pre.append(ml)\n",
    "        if m == test_month[-1]:\n",
    "            ed.append(test_end_date)\n",
    "        else:\n",
    "            ed.append(m+'-'+'28')\n",
    "    return m_l_pre,start_date,ed\n",
    "    \n",
    "ml,sd,ed = get_test_time_list(start_date,test_start_date,test_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_fun(month_list, start_date, end_date):\n",
    "    macro_data_o = get_macro_data(month_list,start_date, end_date)\n",
    "    res = macro_data_o[0]\n",
    "    res_a = macro_data_o[1]\n",
    "    price = macro_data_o[2]\n",
    "    price_month = get_price_month_data(price)\n",
    "    res.index = res['stat_month']\n",
    "    res_a.index = res['stat_month']\n",
    "\n",
    "    sel_data = pd.merge(res_a, price_month, left_index=True, right_index=True).dropna()  # 使用全部宏观数据\n",
    "    data_pure = get_pure_values(sel_data)\n",
    "    columns = data_pure.columns\n",
    "    data_x_start = data_pure[columns[:-1]]\n",
    "    data_y_o = data_pure[columns[-1]]\n",
    "    data_x_o = winsorize_and_standarlize(data_x_start)\n",
    "    data_y_class_o = get_profit_class(data_y_o)\n",
    "    data_x, data_y_class = get_final_data(data_x_o, data_y_class_o)\n",
    "    _, data_y = get_final_data(data_x_o, data_y_o)\n",
    "    # 特征选择\n",
    "    f = FeatureSelection()\n",
    "    n_collinear = f.identify_collinear(data_x, correlation_threshold=0.8) #去除一些共线性特征\n",
    "    lgbm_res = f.identify_importance_lgbm(n_collinear, data_y_class, p_importance=0.9)\n",
    "\n",
    "    estimator = LinearSVC()\n",
    "    wrapper_res = f.wrapper_select(data_x=n_collinear, data_y=data_y_class, n=5, estimator=estimator)\n",
    "\n",
    "    est = LinearSVC(C=0.01, penalty='l1', dual=False)\n",
    "    est1 = RandomForestClassifier()\n",
    "    embedded_res = f.embedded_select(data_x=n_collinear, data_y=data_y_class, estimator=est1)\n",
    "    # LSTM数据准备\n",
    "    lgbm_n_input = len(lgbm_res.columns)\n",
    "    lgbm_x_a = np.array(lgbm_res)\n",
    "    lgbm_x_o = [lgbm_x_a[i: i + seq_len, :] for i in range(lgbm_res.shape[0] - seq_len)]\n",
    "    lgbm_x_l = len(lgbm_x_o)\n",
    "    lgbm_x_array = np.reshape(lgbm_x_o, [lgbm_x_l, seq_len, lgbm_n_input])\n",
    "    lgbm_x = lgbm_x_array[:-n]\n",
    "    lgbm_x_prediction = lgbm_x_array[-n:]\n",
    "    lgbm_y_o = np.array([data_y_class[i + seq_len] for i in range(len(data_y_class) - seq_len)])\n",
    "    lgbm_y_array = np.reshape(lgbm_y_o, [lgbm_y_o.shape[0], 1])\n",
    "    lgbm_y = lgbm_y_array[:-n]\n",
    "    lgbm_y_prediction = lgbm_y_array[-n:]\n",
    "    # print(len(lgbm_y))\n",
    "\n",
    "    embedded_n_input = np.shape(embedded_res)[1]\n",
    "    embedded_x_a = np.array(embedded_res)\n",
    "    embedded_x_o = [embedded_x_a[i: i + seq_len, :] for i in range(embedded_res.shape[0] - seq_len)]\n",
    "    embedded_x_l = len(embedded_x_o)\n",
    "    embedded_x_array = np.reshape(embedded_x_o, [embedded_x_l, seq_len, embedded_n_input])\n",
    "    embedded_x = embedded_x_array[:-n]\n",
    "    embedded_x_predition = embedded_x_array[-n:]\n",
    "    embedded_y_o = np.array([data_y_class[i + seq_len] for i in range(len(data_y_class) - seq_len)])\n",
    "    embedded_y_array = np.reshape(embedded_y_o, [embedded_y_o.shape[0], 1])\n",
    "    embedded_y = embedded_y_array[:-n]\n",
    "\n",
    "    # 获取训练数据和测试数据\n",
    "    # lgbm_train_x,lgbm_test_x,lgbm_train_y,lgbm_test_y = train_test_split(lgbm_x,lgbm_y,test_size=0.3,random_state=0)\n",
    "    # embedded_train_x,embedded_test_x,embedded_train_y,embedded_test_y = train_test_split(embedded_x,embedded_y,test_size=0.3,random_state=0)\n",
    "\n",
    "    lgbm_pre_res = LSTM_fun(lgbm_n_input, lgbm_x, lgbm_y, lgbm_x_prediction, seq_len=seq_len)\n",
    "    embedded_pre_res = LSTM_fun(embedded_n_input, embedded_x, embedded_y, embedded_x_predition, seq_len=seq_len)\n",
    "\n",
    "    # print(lgbm_pre_res)\n",
    "    # print(embedded_pre_res)\n",
    "    pre_res = lgbm_pre_res + embedded_pre_res  # 将两组数据的的预测结果相加\n",
    "    signal = res_output(pre_res)\n",
    "    # print(signal)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_signal(ml,sd,ed):\n",
    "    '''\n",
    "    在时间序列下计算最后三个月的预测值，以此作为决策信号\n",
    "    '''\n",
    "    start_clock = time.clock()\n",
    "    length = len(ml)\n",
    "    l = []\n",
    "    for i in range(length):\n",
    "        month_l = ml[i]\n",
    "        end_d = ed[i]\n",
    "        pre = monthly_fun(month_l,sd,end_d)\n",
    "        l.append(pre)\n",
    "    end_clock = time.clock()\n",
    "    clofk_diff = (end_clock - start_clock)/60\n",
    "    print('time cost:%0.3f'%clofk_diff)\n",
    "    return l\n",
    "pre_res_l = get_pre_signal(ml,sd,ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只适应与n=3的情况\n",
    "def get_buy_sell_signal(pre_res):\n",
    "    '''\n",
    "    由于预测的是未来三个月（n=3）的的情况，预测有重合部分，将重合部分取平均，基于均值做买卖决策，提高精度\n",
    "    此函数只适应与n=3的情况\n",
    "    '''\n",
    "    length = len(pre_res)\n",
    "    l = []\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            l.append(pre_res[0][0])\n",
    "        elif i == 1:\n",
    "            s = (pre_res[0][1]+pre_res[1][0])/2\n",
    "            l.append(s)\n",
    "        elif i == length-1:\n",
    "            l.append((pre_res[i][0]+pre_res[i-1][1]+pre_res[i-2][2])/3)\n",
    "            l.append((pre_res[i][1]+pre_res[i-1][2])/2)\n",
    "            l.append(pre_res[i][2])\n",
    "        else:\n",
    "            t = (pre_res[i][0]+pre_res[i-1][1]+pre_res[i-2][2])/3\n",
    "            l.append(t)\n",
    "    return l\n",
    "\n",
    "bs_signal = get_buy_sell_signal(pre_res_l)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buy_month_list(signal,test_start_date,test_end_date):\n",
    "    test_month = get_month_list(test_start_date,test_end_date)\n",
    "    length = len(signal)\n",
    "    dic = {}\n",
    "    for i in range(n,length+1):\n",
    "        l = []\n",
    "        for j in range(n):\n",
    "            l.append(signal[i-(n-j)])\n",
    "        dic[test_month[i-n]] = l\n",
    "    return dic\n",
    "dic = get_buy_month_list(bs_signal,test_start_date,test_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_buy_signal(dic,test_start_date,test_end_date):\n",
    "    '''\n",
    "    获取每月买卖信号，卖出信号为[0,0,0]、[1,0,0]、[1,1,0]，其余为卖出信号,001、010、011、101、111为买入信号，信号分析没有考虑做空\n",
    "    input:\n",
    "    dic: dic,key为月份，value为对应的信号\n",
    "    '''\n",
    "    test_month = get_month_list(test_start_date,test_end_date)\n",
    "    dic_month_signal = {}\n",
    "    for m in test_month:\n",
    "        l = dic[m]\n",
    "        if (l[0]<0.5) & (l[1]<0.5) & (l[2]<0.5):\n",
    "            dic_month_signal[m] = 0\n",
    "        elif (l[0]>0.5) & (l[1]<0.5) & (l[2]<0.5):\n",
    "            dic_month_signal[m] = 0\n",
    "        elif (l[0]>0.5) & (l[1]>0.5) & (l[2]<0.5):\n",
    "            dic_month_signal[m] = 0\n",
    "        else:\n",
    "            dic_month_signal[m] = 1\n",
    "    v = list(dic_month_signal.values())\n",
    "    df = pd.DataFrame(v,index=dic_month_signal.keys(),columns=['signal'])\n",
    "    return df\n",
    "month_signal = get_month_buy_signal(dic,test_start_date,test_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_profit(stocks,start_date,end_date):\n",
    "    '''\n",
    "    获取月收益率数据，数据为本月相对于上月的增长率，计算时用每月最后MONTH_MEAN_DAY_NUM天的均值\n",
    "    input:\n",
    "    data:dataframe,index为股票代码，values为因子值\n",
    "    start_date:str, 初始日期\n",
    "    end_date:str,终止日期\n",
    "    output:\n",
    "    month_profit_df: Dataframe,columns为每月第一天的收盘价\n",
    "    \n",
    "    '''\n",
    "    start_year = int(start_date[:4])\n",
    "    end_year = int(end_date[:4])\n",
    "    start_month = int(start_date[5:7])\n",
    "    end_month = int(end_date[5:7])\n",
    "    len_month = (end_year - start_year)*12 + (end_month - start_month) + 2\n",
    "    price_list = []\n",
    "    for i in range(len_month):\n",
    "        date = str(start_year+i//12)+'-'+str(start_month+i%12)+'-'+'01'\n",
    "        price = get_price(stocks,fields=['close'],count=1,end_date=date)['close']\n",
    "        price_list.append(price)\n",
    "    month_profit = pd.concat(price_list,axis=0)\n",
    "    v = list(month_profit.values)\n",
    "    month_profit_df = pd.DataFrame(v,index=month_profit.index,columns=['profit'])\n",
    "    return month_profit_df\n",
    "month_profit = get_month_profit(select_index,test_start_date,test_end_date)\n",
    "month_profit_pct = month_profit.pct_change(1,axis=0).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy_profit(month_signal,month_profit_pct):\n",
    "    length_signal = len(month_signal)\n",
    "    length_pct = len(month_profit_pct)\n",
    "    if length_signal != length_pct:\n",
    "        print('input references must have same length')\n",
    "    month_profit_pct_shift = month_profit_pct['profit'].shift(-1)\n",
    "    month_signal['profit'] = month_profit_pct_shift.values\n",
    "\n",
    "    month_signal = month_signal.dropna()\n",
    "    month_signal['profit'][month_signal['signal']==0] = 0\n",
    "    month_signal['selct_profit'] = month_signal['profit']\n",
    "    month_signal['cumprod_profit'] = (month_signal['selct_profit']+1).cumprod()\n",
    "    month_signal['cumsum_profit'] = month_signal['selct_profit'].cumsum()\n",
    "    return month_signal\n",
    "strategy_profit = get_strategy_profit(month_signal,month_profit_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cumprod = strategy_profit['cumprod_profit']\n",
    "p_hs300 = get_price(select_index,start_date=test_start_date,end_date=test_end_date,fields=['close'])\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax0 = fig.add_subplot(2,1,1)\n",
    "ax1 = fig.add_subplot(2,1,2)\n",
    "ax0.plot(sp_cumprod)\n",
    "ax1.plot(p_hs300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
